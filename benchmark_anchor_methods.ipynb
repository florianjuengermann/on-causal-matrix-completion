{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src import generator as gen\n",
    "from src.estimators import SNNEstimator, RidgeEstimator, GapEstimator\n",
    "from src.general_snn import general_snn\n",
    "from src import anchor_matrix as am"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Evaluate the effects of different anchor matrix finding methods:\n",
    "- baseline: finding the _best_ anchor matrix\n",
    "- using multiple good anchor matrices together\n",
    "- using a non-complete matrix and imputing the missing values with averages\n",
    "\n",
    "Test on the following datasets:\n",
    "- Recommendation system, limited MNAR (80x80)\n",
    "- Recommendation system, limited MNAR (160x160)\n",
    "- Recommendation system, general MNAR (80x80)\n",
    "- Recommendation system, general MNAR (160x160)\n",
    "\n",
    "Additional tests:\n",
    "- when using multiple anchor matrices, how many estimates do we need?\n",
    "- non-complete matrix, using whole matrix vs submatrix averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_limited_MNAR(rating_matrix, P, biclique_search, estimator, num_estimates=1, num_runs=1, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    RMSEs = []\n",
    "    MAEs = []\n",
    "    Times = []\n",
    "    for _ in range(num_runs):\n",
    "        D = rng.binomial(1, P)\n",
    "        Y = rating_matrix.copy()\n",
    "        Y[D == 0] = np.nan\n",
    "        rtime = time.time()\n",
    "        estimator.prepare(Y, D)\n",
    "        Y_restored = general_snn(\n",
    "          D, Y,\n",
    "          estimator=estimator,\n",
    "          biclique_search=biclique_search,\n",
    "          num_estimates=num_estimates,\n",
    "          min_val=1, max_val=5,\n",
    "          print_progress=True\n",
    "        )\n",
    "        Times.append(time.time() - rtime)\n",
    "        Error = (rating_matrix - Y_restored).flatten()\n",
    "        RMSEs.append(np.sqrt(np.mean(Error ** 2)))\n",
    "        MAEs.append(np.mean(np.abs(Error)))\n",
    "    return {\n",
    "        \"RMSE\": {'mean': np.mean(RMSEs), 'std': np.std(RMSEs)},\n",
    "        \"MAE\": {'mean': np.mean(MAEs), 'std': np.std(MAEs)},\n",
    "        \"time\": {'mean': np.mean(Times), 'std': np.std(Times)}\n",
    "    }\n",
    "\n",
    "def run_general_MNAR(latent_movie_matrix, inv_scale, biclique_search, estimator, num_estimates=1, num_runs=1, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    RMSEs = []\n",
    "    MAEs = []\n",
    "    Times = []\n",
    "    for _ in range(num_runs):\n",
    "        rating_matrix, P, latent_movie_matrix = gen.getRatingAndPropensityMatrix_general(latent_movie_matrix, inv_scale, seed=rng)\n",
    "        D = np.random.binomial(1, P) # not really needed as P[i,j] âˆˆ {0, 1}\n",
    "        Y = rating_matrix.copy()\n",
    "        Y[D == 0] = np.nan\n",
    "        rtime = time.time()\n",
    "        estimator.prepare(Y, D)\n",
    "        Y_restored = general_snn(\n",
    "          D, Y,\n",
    "          estimator=estimator,\n",
    "          biclique_search=biclique_search,\n",
    "          num_estimates=num_estimates,\n",
    "          min_val=1, max_val=5,\n",
    "          print_progress=True\n",
    "        )\n",
    "        Times.append(time.time() - rtime)\n",
    "        Error = (rating_matrix - Y_restored).flatten()\n",
    "        RMSEs.append(np.sqrt(np.mean(Error ** 2)))\n",
    "        MAEs.append(np.mean(np.abs(Error)))\n",
    "    return {\n",
    "        \"RMSE\": {'mean': np.mean(RMSEs), 'std': np.std(RMSEs)},\n",
    "        \"MAE\": {'mean': np.mean(MAEs), 'std': np.std(MAEs)},\n",
    "        \"time\": {'mean': np.mean(Times), 'std': np.std(Times)}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix_80,  P_80  = gen.getRatingAndPropensityMatrix(inv_scale=1)\n",
    "rating_matrix_100, P_100 = gen.getRatingAndPropensityMatrix(inv_scale=0.8)\n",
    "rating_matrix_160, P_160 = gen.getRatingAndPropensityMatrix(inv_scale=0.5)\n",
    "_, _, latent_movie_matrix_80  = gen.getRatingAndPropensityMatrix_general(inv_scale=1, seed=0)\n",
    "_, _, latent_movie_matrix_100  = gen.getRatingAndPropensityMatrix_general(inv_scale=0.8, seed=0)\n",
    "_, _, latent_movie_matrix_160 = gen.getRatingAndPropensityMatrix_general(inv_scale=0.5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " biclique_find RidgeEstimator\n",
      " 80/80\n",
      " 100/100\n",
      " 80/80\n",
      " 100/100\n",
      "\n",
      " biclique_find SNNEstimator\n",
      " 80/80\n",
      " 100/100\n",
      " 80/80\n",
      " 100/100\n",
      "\n",
      " biclique_random RidgeEstimator\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n",
      "\n",
      " biclique_random SNNEstimator\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n",
      "\n",
      " whole_matrix RidgeEstimator\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n",
      "\n",
      " whole_matrix SNNEstimator\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n",
      " 80/80\n",
      " 100/100\n",
      " 160/160\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "  RidgeEstimator(reg_alpha=lambda sz, ratio: 0.001),\n",
    "  SNNEstimator(spectral_rank_fun=lambda s, m, n: np.sum(s>=0.001)),\n",
    "]\n",
    "biclique_methods = [\n",
    "  am.biclique_find,\n",
    "  am.biclique_random,\n",
    "  am.whole_matrix,\n",
    "]\n",
    "num_runs = 1\n",
    "# res1: method -> estimator -> dataset -> res\n",
    "res1 = {method.__name__: {est.__class__.__name__:{} for est in estimators} for method in biclique_methods}\n",
    "for biclique_method in biclique_methods:\n",
    "    num_estimates = 5 if biclique_method == am.biclique_random else 1\n",
    "    for estimator in estimators:\n",
    "        est = GapEstimator(estimator, avg_base=\"submatrix\") if biclique_method == am.whole_matrix else estimator\n",
    "        m_name = biclique_method.__name__\n",
    "        est_name = estimator.__class__.__name__\n",
    "        print(\"\\n\", m_name, est_name)\n",
    "        res1[m_name][est_name][\"l080\"] = run_limited_MNAR(rating_matrix_80, P_80, biclique_method, est, num_estimates, num_runs, 0)\n",
    "        res1[m_name][est_name][\"l100\"] = run_limited_MNAR(rating_matrix_100, P_100, biclique_method, est, num_estimates, num_runs, 0)\n",
    "        if biclique_method != am.biclique_find:\n",
    "            res1[m_name][est_name][\"l160\"] = run_limited_MNAR(\n",
    "                rating_matrix_160, P_160, biclique_method, est, num_estimates, num_runs, 0)\n",
    "        res1[m_name][est_name][\"g080\"] = run_general_MNAR(latent_movie_matrix_80, 1, biclique_method, est, num_estimates, num_runs, 0)\n",
    "        res1[m_name][est_name][\"g100\"] = run_general_MNAR(latent_movie_matrix_100, 0.8, biclique_method, est, num_estimates, num_runs, 0)\n",
    "        if biclique_method != am.biclique_find:\n",
    "            res1[m_name][est_name][\"g160\"] = run_general_MNAR(\n",
    "                latent_movie_matrix_160, 0.5, biclique_method, est, num_estimates, num_runs, 0)\n",
    "\n",
    "with open('data/res1.json', 'w') as outfile:\n",
    "    json.dump(res1, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Additional Tests\n",
    "\n",
    "### 2.1 How many estimates do we need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num estimates: 1\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      "Num estimates: 3\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      "Num estimates: 5\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      "Num estimates: 10\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      "Num estimates: 20\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n"
     ]
    }
   ],
   "source": [
    "estimator = RidgeEstimator(reg_alpha=lambda sz, ratio: 0.001)\n",
    "biclique_method = am.biclique_random\n",
    "\n",
    "num_runs = 5\n",
    "num_estimates_vals = [1, 3, 5, 10, 20]\n",
    "# res2: num_est -> dataset -> res\n",
    "res2 = {}\n",
    "for num_estimates in num_estimates_vals:\n",
    "    res2[num_estimates] = {}\n",
    "    print(f\"Num estimates: {num_estimates}\")\n",
    "    res2[num_estimates][\"l80\"] = run_limited_MNAR(rating_matrix_80, P_80, biclique_method, estimator, num_estimates, num_runs)\n",
    "    res2[num_estimates][\"g80\"] = run_general_MNAR(latent_movie_matrix_80, 1, biclique_method, estimator, num_estimates, num_runs)\n",
    "\n",
    "with open('data/res2.json', 'w') as outfile:\n",
    "    json.dump(res2, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Whole matrix, use total or submatrix averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RidgeEstimator submatrix\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n",
      "\n",
      " RidgeEstimator complete\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n",
      "\n",
      " SNNEstimator submatrix\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n",
      "\n",
      " SNNEstimator complete\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n",
      " 80/80\n",
      " 80/80\n",
      " 80/80\n",
      " 100/100\n",
      " 100/100\n",
      " 100/100\n",
      " 160/160\n",
      " 160/160\n",
      " 160/160\n"
     ]
    }
   ],
   "source": [
    "base_estimators = [\n",
    "  RidgeEstimator(reg_alpha=lambda sz, ratio: 0.001),\n",
    "  SNNEstimator(spectral_rank_fun=lambda s, m, n: np.sum(s>=0.001)),\n",
    "]\n",
    "\n",
    "biclique_method = am.whole_matrix\n",
    "\n",
    "num_runs = 3\n",
    "avg_basis = [\"submatrix\", \"complete\"]\n",
    "# res3: estimator -> avg_base -> dataset -> res\n",
    "res3 = {est.__class__.__name__:{avg_base: {} for avg_base in avg_basis} for est in estimators}\n",
    "for base_estimator in base_estimators:\n",
    "  for avg_base in avg_basis:\n",
    "      est = GapEstimator(base_estimator, avg_base=avg_base) \n",
    "      ename = base_estimator.__class__.__name__\n",
    "      print(\"\\n\", ename, avg_base)\n",
    "      res3[ename][avg_base][\"l80\"] = run_limited_MNAR(rating_matrix_80, P_80, biclique_method, est, 1, num_runs)\n",
    "      res3[ename][avg_base][\"l100\"] = run_limited_MNAR(rating_matrix_100, P_100, biclique_method, est, 1, num_runs)\n",
    "      res3[ename][avg_base][\"l160\"] = run_limited_MNAR(rating_matrix_160, P_160, biclique_method, est, 1, num_runs)\n",
    "      res3[ename][avg_base][\"g80\"] = run_general_MNAR(latent_movie_matrix_80, 1, biclique_method, est, 1, num_runs)\n",
    "      res3[ename][avg_base][\"g100\"] = run_general_MNAR(latent_movie_matrix_100, 0.8, biclique_method, est, 1, num_runs)\n",
    "      res3[ename][avg_base][\"g160\"] = run_general_MNAR(latent_movie_matrix_160, 0.5, biclique_method, est, 1, num_runs)\n",
    "\n",
    "with open('data/res3.json', 'w') as outfile:\n",
    "    json.dump(res3, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': {'mean': 0.032498122274896575, 'std': 0.0},\n",
       " 'MAE': {'mean': 0.00573244788127733, 'std': 0.0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_general_MNAR(\n",
    "  latent_movie_matrix_80,\n",
    "  inv_scale=1,\n",
    "  biclique_search=am.biclique_find,\n",
    "  estimator=SNNEstimator(spectral_rank_fun=lambda s, m, n: np.sum(s>=0.001)),\n",
    "  num_estimates=1,\n",
    "  num_runs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': {'mean': 0.02238232337683985, 'std': 0.0},\n",
       " 'MAE': {'mean': 0.005750886642592301, 'std': 0.0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_general_MNAR(\n",
    "  latent_movie_matrix_80,\n",
    "  inv_scale=1,\n",
    "  biclique_search=am.biclique_find,\n",
    "  estimator=RidgeEstimator(reg_alpha=lambda sz, ratio: 0.001),\n",
    "  num_estimates=1,\n",
    "  num_runs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': {'mean': 0.20820581852734021, 'std': 0.0},\n",
       " 'MAE': {'mean': 0.12328157387088565, 'std': 0.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_general_MNAR(\n",
    "  latent_movie_matrix_80,\n",
    "  inv_scale=1,\n",
    "  biclique_search=am.whole_matrix,\n",
    "  estimator=GapEstimator(\n",
    "    estimator=SNNEstimator(spectral_rank_fun=lambda s, m, n: np.sum(s>=0.001)),\n",
    "    #estimator=RidgeEstimator(reg_alpha=lambda sz, ratio: 0.001),\n",
    "    #avg_base=\"submatrix\",\n",
    "    avg_base=\"complete\",\n",
    "  ),\n",
    "  num_estimates=1,\n",
    "  num_runs=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
